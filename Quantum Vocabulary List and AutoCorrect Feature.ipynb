{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e34dfe0",
   "metadata": {},
   "source": [
    "# Quantum Vocabulary List and AutoCorrect Feature\n",
    "## 622 published articles in New Atlas (https://newatlas.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63566734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import textdistance\n",
    "import Levenshtein as lev\n",
    "\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "\n",
    "import networkx as nx\n",
    "stop_words = list(stopwords.words('english'))\n",
    "\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6440e0",
   "metadata": {},
   "source": [
    "**Project Scope: Now the dataset including 622 unique quantum articles**. \n",
    "<br>The articles published from *2003-09-15* to *2022-12-01* in https://newatlas.com/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2861b8fb",
   "metadata": {},
   "source": [
    "## Creating a Quantum Word List\n",
    "Having a list of words which are appeared in a special subject (here the Quantum) is helpful in many porpuses, such as: reading, applying and comrehending the *special text*, *creating a special vocabulary* and  *Designing autocorrect feature* and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5054da5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Article</th>\n",
       "      <th>Published On</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBM brings quantum computing to the masses</td>\n",
       "      <td>['Jon Simon Feature Photo Service For Ibm', 'C...</td>\n",
       "      <td>For the first time, IBM Research has thrown op...</td>\n",
       "      <td>2016-05-06 07:11:29.000</td>\n",
       "      <td>https://newatlas.com/quantum-processor-qubits-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diamond-based quantum computer paired with sup...</td>\n",
       "      <td>['Pawsey Supercomputing Research Centre', 'Mic...</td>\n",
       "      <td>Quantum computing may have just taken a major ...</td>\n",
       "      <td>2022-06-03 06:39:18.610</td>\n",
       "      <td>https://newatlas.com/computers/quantum-compute...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0         IBM brings quantum computing to the masses   \n",
       "1  Diamond-based quantum computer paired with sup...   \n",
       "\n",
       "                                              Author  \\\n",
       "0  ['Jon Simon Feature Photo Service For Ibm', 'C...   \n",
       "1  ['Pawsey Supercomputing Research Centre', 'Mic...   \n",
       "\n",
       "                                             Article             Published On  \\\n",
       "0  For the first time, IBM Research has thrown op...  2016-05-06 07:11:29.000   \n",
       "1  Quantum computing may have just taken a major ...  2022-06-03 06:39:18.610   \n",
       "\n",
       "                                                Link  \n",
       "0  https://newatlas.com/quantum-processor-qubits-...  \n",
       "1  https://newatlas.com/computers/quantum-compute...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Quantum_Articles_NewAtlas.csv\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a310f6",
   "metadata": {},
   "source": [
    "### Quantum Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae0357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_function(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    # Removing punctuations\n",
    "    text = text.replace(\"’s\", \"\")\n",
    "    text = text.replace(\"n’t\" , \" \")\n",
    "    text = text.replace(\"’d\", \"\")\n",
    "    text = text.replace(\"’ve\", \"\")    \n",
    "    #text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    #text = re.sub(\" \\d+\", \" \", text)\n",
    "    \n",
    "    #Remving numbers\n",
    "    #text = re.sub(r'[0-9]+', '', text)\n",
    "    \n",
    "    #Remving all characters but alphabets\n",
    "    text=re.sub(\"[^A-Z a-z]\", ' ', text)\n",
    "    \n",
    "    #Removing multiple spaces\n",
    "    text = re.sub(' +', ' ', text)\n",
    "\n",
    "    \n",
    "    # Tokenizing\n",
    "    Token_L= text.split()\n",
    "    Token_L = [token.replace(\" \",\"\") for token in Token_L]\n",
    "    \n",
    "    # Removing stopwords\n",
    "    Token_L = [token for token in Token_L if not token in stop_words]\n",
    "    \n",
    "    # Removing Charghters of formulas(such as c, v, q and etc.)\n",
    "    Token_L = [token for token in Token_L if len(token)>2]\n",
    "    \n",
    "    # Lemmatization\n",
    "    Token_L = [token.lemma_ for token in nlp(\" \".join(Token_L))]    \n",
    "    \n",
    "    return(Token_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ea8f8c",
   "metadata": {},
   "source": [
    "*To prevent following Error word_L list is separated in 3 parts then they will be unified*\n",
    "<br>ValueError: [E088] Text of length 2624523 exceeds maximum of 1000000. The parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f3c5682",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 =\" \".join(df[\"Article\"][:200]) \n",
    "word_L1 = common_function(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af39e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 =\" \".join(df[\"Article\"][200:400]) \n",
    "word_L2 = common_function(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4987c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 =\" \".join(df[\"Article\"][400:500]) \n",
    "word_L3 = common_function(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "672f22b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 =\" \".join(df[\"Article\"][500:600]) \n",
    "word_L4 = common_function(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ffc343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text5 =\" \".join(df[\"Article\"][600:]) \n",
    "word_L5 = common_function(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4bea1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341709"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_L = word_L1 + word_L2 + word_L3 + word_L4 + word_L5\n",
    "len(word_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0124d56",
   "metadata": {},
   "source": [
    "### Quantum Vocabulary set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11b53755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20508"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_vocab = set(word_L)\n",
    "len(Q_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "627cb8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring stopwords, roughly there are (341709) words in the text. including (20508) unique words.\n"
     ]
    }
   ],
   "source": [
    "print(\"Ignoring stopwords, roughly there are ({}) words in the text. including ({}) unique words.\".format(len(word_L) ,  len(Q_vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6754d57",
   "metadata": {},
   "source": [
    "### AutoCorrect Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e9eba",
   "metadata": {},
   "source": [
    "To have AutoCorrector the probebility matters most, so creating a Collections Counter (word_frequancy) is necessary.\n",
    "<br>Then the autocorector feature offer some nearest word to what is wrote by user, in realtime.\n",
    "<br>This sort of feature is offered in articles by **Jaccard Similarity** method the capability of this appraoch has been challenged by another appraoch, which is **Levenshtein Distance** method.\n",
    "<br>**Conclusion**: The time cost of both methods are appropriate, the performance of **Levenshtein Distance** is much more better. but why?\n",
    "<br>*Whatevere it is in AutoCorrect feature the difference between targeted word and suggestions matters not ther similarities.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cac80775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most common words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('quantum', 3051),\n",
       " ('one', 2403),\n",
       " ('use', 2234),\n",
       " ('new', 1905),\n",
       " ('auction', 1809),\n",
       " ('time', 1687),\n",
       " ('make', 1653),\n",
       " ('first', 1555),\n",
       " ('year', 1358),\n",
       " ('could', 1293)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collectin Countor of Words\n",
    "word_frequency = {}  \n",
    "word_frequency = Counter(word_L)\n",
    "\n",
    "print(\"Top 10 most common words:\")\n",
    "word_frequency.most_common()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55e5ba3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency['Computing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4085a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collectin Countor of Propbabilities of Words (regarding theie frequencies)\n",
    "probability = {}     \n",
    "    \n",
    "for w in word_frequency.keys():\n",
    "    probability[w] = word_frequency[w]/sum(word_frequency.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e2b10a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantum 0.009\n",
      "one 0.007\n",
      "use 0.007\n",
      "new 0.006\n",
      "auction 0.005\n",
      "time 0.005\n",
      "make 0.005\n",
      "first 0.005\n",
      "year 0.004\n",
      "could 0.004\n"
     ]
    }
   ],
   "source": [
    "# The probability of appearing top 10 words in articles\n",
    "sort_probability = sorted(probability.items(), key=lambda x: x[1], reverse=True)\n",
    "for i in sort_probability[:10]:\n",
    "    print(i[0], round(i[1],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a82f39",
   "metadata": {},
   "source": [
    "#### Approach 1: AutoCorrect using Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8ead665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrector_J(word):\n",
    "    word = word.lower()\n",
    "    if word in Q_vocab:\n",
    "        return(word)\n",
    "    else:\n",
    "        sim = [1-(textdistance.Jaccard(qval=1).distance(w,word)) for w in word_frequency.keys()]\n",
    "        df0 = pd.DataFrame.from_dict(probability, orient='index').reset_index()\n",
    "        df0 = df0.rename(columns={'index':'Offered Words', 0:'Similarity'})\n",
    "        df0['Similarity'] = sim\n",
    "        output = df0.sort_values('Similarity', ascending=False).head(3)\n",
    "        return(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcc835f",
   "metadata": {},
   "source": [
    "#### Approach 2: AutoCorrect using Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17ada5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrector_L(word):\n",
    "    word = word.lower()\n",
    "    if word in Q_vocab:\n",
    "        return(word)\n",
    "    else:\n",
    "        dist = [lev.distance(word,w) for w in word_frequency.keys()]\n",
    "        df0 = pd.DataFrame.from_dict(probability, orient='index').reset_index()\n",
    "        df0 = df0.rename(columns={'index':'Offered Words', 0: \"Distance\"})\n",
    "        df0['Distance'] = dist\n",
    "        output = df0.sort_values('Distance').head(3)\n",
    "        return(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4156ff",
   "metadata": {},
   "source": [
    "#### Which method is better? *Levenshtein Distance* vs. *Jaccard Similarity*\n",
    "To evaluate performance 3 wrong words will be applied:\n",
    "<br>*quantom* (the wrong spell of *quantum*)\n",
    "<br>*speentronic* (the wrong spell of *spintronic*)\n",
    "<br>*relitivity* (the wrong spell of *relativity*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c00356e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sugestion for (quantom) Jaccard method:\n",
      "     Offered Words  Similarity\n",
      "217         amount    0.857143\n",
      "9          quantum    0.750000\n",
      "5509       quantop    0.750000 \n",
      "\n",
      "Sugestion for (quantom) LevenShtein method:\n",
      "      Offered Words  Distance\n",
      "9           quantum         1\n",
      "5509        quantop         1\n",
      "15780        quantu         2 \n",
      "\n",
      "\n",
      "Sugestion for (speentronic) Jaccard method:\n",
      "      Offered Words  Similarity\n",
      "7219    electronsin    0.833333\n",
      "19856     inspector    0.818182\n",
      "6640      reception    0.818182 \n",
      "\n",
      "Sugestion for (speentronic) LevenShtein method:\n",
      "      Offered Words  Distance\n",
      "2009     spintronic         2\n",
      "624      electronic         4\n",
      "12510     eccentric         5 \n",
      "\n",
      "\n",
      "Sugestion for (relitivity) Jaccard method:\n",
      "      Offered Words  Similarity\n",
      "1457     relativity    0.818182\n",
      "13768   intuitively    0.750000\n",
      "4238    resistivity    0.750000 \n",
      "\n",
      "Sugestion for (relitivity) LevenShtein method:\n",
      "      Offered Words  Distance\n",
      "1457     relativity         1\n",
      "4238    resistivity         2\n",
      "13158     relativit         2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for w in [\"quantom\", \"speentronic\", \"relitivity\"]:\n",
    "    print(\"\\nSugestion for ({}) Jaccard method:\".format(w))\n",
    "    print(autocorrector_J(w),\"\\n\")\n",
    "    print(\"Sugestion for ({}) LevenShtein method:\".format(w))\n",
    "    print(autocorrector_L(w),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0aa1df",
   "metadata": {},
   "source": [
    "**Result**: The *LevenShtein mothod* worked much more better, in suggesting words in first of row."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
